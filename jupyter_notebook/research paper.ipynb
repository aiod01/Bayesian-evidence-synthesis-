{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model: Ambulance + Overdose\n",
    "\n",
    "\n",
    "\n",
    "## Ambulance Call-outs Model\n",
    "\n",
    "$n_{A}$: sample size   \n",
    "$x_{A}$: the total number who confirmed they did call an ambulance  \n",
    "$p_{A}$: probability of a person call an ambulance   \n",
    "\n",
    "$$x_{A} \\sim Bin(n_{A},p_{A})$$\n",
    "\n",
    "**We assume $n_{A}=1000, p_A = 0.8$.**  \n",
    "**Suppose the prior of $p_A$ is noninformative.** \n",
    "$$p(p_A) \\sim Beta(1,1)$$\n",
    "\n",
    "## Overdose Model\n",
    "Now we plug in this values into the overdose model and obtain possible $O_t$ values **assuming we have $U_t$ values.**\n",
    "Also, we have priors.\n",
    "\n",
    "\n",
    "$$z_{t} \\sim N(\\mu, \\sigma^{2})$$  \n",
    "$$\\lambda_{t}^{OD} = \\exp(z_{t})$$  \n",
    "$$O_{t} \\sim Poi(\\lambda_{t}^{OD}N)$$  \n",
    "$$U_t \\sim Bin(O_t, p_A)$$  \n",
    "For simplicity we set N =10000 for now. We need to generate reasonable $U_t$ values first. Note that $U_t$ comes from $\\mu, \\sigma$ following all the way through the overdose model.  \n",
    "\n",
    "\n",
    "\n",
    "$\\mu=\\log0.05, \\sigma=1, N=10000$.   \n",
    "We suppose survey data exists: ($n_A, x_A$) known.  \n",
    "\n",
    "**We set for our prior parameters:** $$\\mu \\sim U(-10,0)$$  $$\\sigma \\sim U(0,5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function that generate data from simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_ambulance_overdoses(random=1, mu_z=np.log(0.05), sigma_z=1.,\n",
    "                            N=10000, p_a=0.8, n_a=1000, n_T=12):\n",
    "    '''\n",
    "    Simulate overdoses data, ambulance-call outs survey data and related variables \n",
    "    -----------\n",
    "    mu_z- float \n",
    "        log rate for lambda\n",
    "    \n",
    "    sigma_z -float\n",
    "        variance of log lambda\n",
    "    \n",
    "    N - int\n",
    "        Total size of population\n",
    "        \n",
    "    p_a - float\n",
    "        probability of calling ambulance at the scene of overdose\n",
    "    \n",
    "    n_a - int\n",
    "        total number of survey\n",
    "    \n",
    "    n_T - int\n",
    "        number of time points  \n",
    "    '''\n",
    "    #set.seed(1)\n",
    "    np.random.seed(random)\n",
    "    \n",
    "    # generate z_t values\n",
    "    zt = np.random.normal(loc=mu_z, scale = sigma_z, size = n_T)\n",
    "    \n",
    "    # convert into lambda_t\n",
    "    lmd_t = np.exp(zt)\n",
    "    \n",
    "    # generate O_t data set\n",
    "    o_t = np.random.poisson(lmd_t*N)\n",
    "    \n",
    "    # generate U_t data set\n",
    "    u_t = np.random.binomial(n=o_t, p=p_a)\n",
    "    \n",
    "    # generate x_t data set\n",
    "    x_a = np.random.binomial(n=n_a, p=p_a, size =12)\n",
    "    \n",
    "    return {'o_t':o_t, 'u_t':u_t, 'x_a':x_a, 'n_a':n_a,'N':N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= sim_ambulance_overdoses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o_t': array([2475,  262,  318,  149, 1151,   39, 2997,  242,  702,  377, 2088,\n",
       "          76]),\n",
       " 'u_t': array([1969,  217,  253,  119,  934,   34, 2392,  196,  569,  308, 1655,\n",
       "          55]),\n",
       " 'x_a': array([799, 798, 795, 816, 805, 794, 793, 780, 773, 779, 788, 813]),\n",
       " 'n_a': 1000,\n",
       " 'N': 10000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here we want to save the first three columns as data frame to use in JAGS\n",
    "data_copy = data.copy()\n",
    "data_copy.pop('n_a')\n",
    "data_copy.pop('N')\n",
    "df_pd = pd.DataFrame(data=data_copy)\n",
    "df_pd\n",
    "df_pd.to_csv('../Rcodes/basic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that data.copy will actually copy the object while **data_copy=data** will only make the new pointer points the same object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o_t': array([2475,  262,  318,  149, 1151,   39, 2997,  242,  702,  377, 2088,\n",
       "          76]),\n",
       " 'u_t': array([1969,  217,  253,  119,  934,   34, 2392,  196,  569,  308, 1655,\n",
       "          55]),\n",
       " 'x_a': array([799, 798, 795, 816, 805, 794, 793, 780, 773, 779, 788, 813])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o_t': array([2475,  262,  318,  149, 1151,   39, 2997,  242,  702,  377, 2088,\n",
       "          76]),\n",
       " 'u_t': array([1969,  217,  253,  119,  934,   34, 2392,  196,  569,  308, 1655,\n",
       "          55]),\n",
       " 'x_a': array([799, 798, 795, 816, 805, 794, 793, 780, 773, 779, 788, 813]),\n",
       " 'n_a': 1000,\n",
       " 'N': 10000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data):\n",
    "    N = data['N']\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # priors \n",
    "        p_a = pm.Beta('p_a', alpha=1, beta=1)\n",
    "        # note that this prior is to be changed later\n",
    "        mu_z = pm.Uniform('mu_z', -10, 0)\n",
    "        sigma_z = pm.Uniform('sigma_z',0,5)\n",
    "        \n",
    "        # latent variables\n",
    "        z_t = pm.Normal('z_t', mu=mu_z, sigma=sigma_z, shape=(12,))\n",
    "        lmb_t = pm.Deterministic('lmb_t', tt.exp(z_t))\n",
    "#       o_t = pm.Poisson('o_t', lmb_t*N)\n",
    "        o_t = pm.Gamma('o_t', mu=lmb_t*N , sigma=tt.sqrt(lmb_t*N), shape=(12,) )\n",
    "        # MCMC with discrete random variable is hard to do sampling...\n",
    "        # We approximate this to Gamma dist\n",
    "        \n",
    "        \n",
    "        #likelihood \n",
    "        pm.Poisson('u_t', o_t*p_a, observed=data['u_t'])\n",
    "        pm.Binomial('x_a', n=data['n_a'], p =p_a, observed=data['x_a'])\n",
    "        \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between my prior and Mike's prior exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO (theano.gof.compilelock): Refreshing lock /Users/hyeongcheolpark/.theano/compiledir_Darwin-19.3.0-x86_64-i386-64bit-i386-3.7.4-64/lock_dir/lock\n",
      "Multiprocess sampling (3 chains in 2 jobs)\n",
      "NUTS: [o_t, z_t, sigma_z, mu_z, p_a]\n",
      "Sampling 3 chains: 100%|██████████| 4500/4500 [00:41<00:00, 109.43draws/s]\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(1000, chains=3, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Did I use garge samples before the traceplot become stable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trace['o_t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of $O_t$\n",
    "$O_t$ is the variable of interest that we can never get data set. \n",
    "Boxplot of $O_t$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a4_dims = (16,7)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "df = pd.DataFrame(data=trace['o_t'], columns=range(1,13))\n",
    "ax=sns.boxplot(data=df)\n",
    "plt.title(\"posterior samples of $O_t$\")\n",
    "ax.set_xlabel('months')\n",
    "ax.set_ylabel('$O_t$')\n",
    "ax2 = plt.plot(range(0,12), data['o_t'],'ro')\n",
    "fig.savefig('../latex/Figures/earlyresult1_ot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace['o_t'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ot=np.sum(trace['o_t'],axis=1)\n",
    "plt.hist(sum_ot,bins=30);\n",
    "plt.title('histogram of the summation of $O_t$');\n",
    "plt.xlabel('summation of $O_t$');\n",
    "plt.ylabel('Frequency');\n",
    "plt.savefig('../latex/Figures/hist_sum_ot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Predictive Check\n",
    "\n",
    "## PPC: $U_t$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace, samples=1000, model=model, random_seed=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to see if there is discrepency between original data set (likelihood) and the posterior predictive distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "plt.title(\"PPC: U_t\")\n",
    "df = pd.DataFrame(data=ppc['u_t'], columns=range(1,13))\n",
    "ax=sns.boxplot(data=df)\n",
    "plt.title(\"posterior predictive values of $U_t$\")\n",
    "ax.set_xlabel('months')\n",
    "ax.set_ylabel('$U_t$')\n",
    "ax2 = plt.plot(range(12), data['u_t'],'ro')\n",
    "fig.savefig('../latex/Figures/early_r_ppc1_ut.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPC: $x_A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['x_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['x_a'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the shape, so we will have 12000 posterior predictive \n",
    "# samples and we plot them with only one 0.8 red point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "df= pd.DataFrame(data=ppc['x_a'], columns=range(1,13))\n",
    "ax=sns.boxplot(data=df)\n",
    "ax.set_title('posterior predictive values of $x_A$')\n",
    "ax.set_xlabel('month')\n",
    "ax.set_ylabel('$x_A$')\n",
    "ax2 = plt.plot(range(12), data['x_a'],'ro')\n",
    "fig.savefig('../latex/Figures/early_r_ppc1_xt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['x_a'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior predictive values are consistent with the expected value 800.\n",
    "We have the most variation between the PPC and the likelihood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As A Function ($P_A$(biased), N)\n",
    "We want to see the effect of $P_A$: how much effect does $P_A$ has on our inference?  \n",
    "bias term on $p_A$:  \n",
    "Bias = $\\theta -\\hat{\\theta} = p_A- \\hat{p}_A$   \n",
    "$\\hat{p}_A = p_A + bias(p_A)$  \n",
    "\n",
    "$p_A$ still be set to 0.8 but $\\hat{p}_A$ will have some bias. \n",
    "\n",
    "$p_A$ is inferred from survey data ($n_A, x_A$). Since our estimation of the parameter is from there, we suppose that our survey data is contaminated. That is, our estimation of $p_A$ has a bias term and see how it affects the estimaton of $O_t$, our ultimate interest.\n",
    "\n",
    "Probably the common case is underestimate the $p_A$. This can happen since drug addicts or witnesses may not want to reveal that they called aubulance for some credential concern.  \n",
    "\n",
    "Hence, we build a function that can have bias argument so that the survey data (likelihood) may lead underestimated $p_A$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_ambulance_overdoses_bias(random = 1, mu_z=np.log(0.05), sigma_z=1.,\n",
    "                            N=10000, p_a=0.8, bias = -0.2, n_a=1000, n_T=12):\n",
    "    '''\n",
    "    Simulate overdoses data, ambulance-call outs survey data and related variables considering \n",
    "    possible bias term for p_a\n",
    "    -----------\n",
    "    mu_z- float \n",
    "        log rate for lambda\n",
    "    \n",
    "    sigma_z -float\n",
    "        variance of log lambda\n",
    "    \n",
    "    N - int\n",
    "        Total size of population\n",
    "        \n",
    "    p_a - float\n",
    "        probability of calling ambulance at the scene of overdose\n",
    "        \n",
    "    bias - float\n",
    "        bias term affecting the survey data \n",
    "    \n",
    "    n_a - int\n",
    "        total number of survey\n",
    "    \n",
    "    n_T - int\n",
    "        number of time points  \n",
    "    '''\n",
    "    #set.seed(1)\n",
    "    np.random.seed(random)\n",
    "    \n",
    "    # generate z_t values\n",
    "    zt = np.random.normal(loc=mu_z, scale = sigma_z, size = n_T)\n",
    "    \n",
    "    # convert into lambda_t\n",
    "    lmd_t = np.exp(zt)\n",
    "    \n",
    "    # generate O_t data set\n",
    "    o_t = np.random.poisson(lmd_t*N)\n",
    "    \n",
    "    # generate U_t data set\n",
    "    u_t = np.random.binomial(n=o_t, p=p_a)\n",
    "    \n",
    "    # generate x_t data set\n",
    "    x_a = np.random.binomial(n=n_a, p=p_a+ bias, size=12)\n",
    "    \n",
    "    return {'o_t':o_t, 'u_t':u_t, 'x_a':x_a, 'n_a':n_a,'N':N, 'bias':bias}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_p_a= sim_ambulance_overdoses_bias(random=1, mu_z=np.log(0.05), sigma_z=1.,\n",
    "                            N=10000, p_a=0.8, bias = -0.2, n_a=1000, n_T=12)\n",
    "under_p_a.pop('n_a')\n",
    "under_p_a.pop('N')\n",
    "df_pd = pd.DataFrame(data=under_p_a)\n",
    "df_pd\n",
    "df_pd.to_csv('../Rcodes/under_p_a_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_p_a= sim_ambulance_overdoses_bias(random=1, mu_z=np.log(0.05), sigma_z=1.,\n",
    "                            N=10000, p_a=0.8, bias = 0.1, n_a=1000, n_T=12)\n",
    "over_p_a.pop('n_a')\n",
    "over_p_a.pop('N')\n",
    "df_pd = pd.DataFrame(data=over_p_a)\n",
    "df_pd\n",
    "df_pd.to_csv('../Rcodes/over_p_a_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's make a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_robust(random=1, mu_z=np.log(0.05), sigma_z=1.,\n",
    "                            N=10000, p_a=0.8, bias = -0.2, n_a=1000, n_T=12):\n",
    "    data = sim_ambulance_overdoses_bias(random=random, mu_z=mu_z, sigma_z=sigma_z,\n",
    "                            N=N, p_a=p_a, bias = bias, n_a=n_a, n_T=n_T)\n",
    "    model = create_model(data)\n",
    "    with model:\n",
    "        trace = pm.sample(1000, chains=2,random_seed=1)\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=1000, model=model,random_seed=1)\n",
    "    \n",
    "    return {'data':data, 'model':model, 'trace':trace, 'ppc':ppc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_list_unbiased = test_robust(bias = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_under = test_robust()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_over = test_robust(bias = +0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is some weird process going under, let us check the acutal data sets here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(my_list_unbiased['data']['u_t'])\n",
    "print(my_list_under['data']['u_t'])\n",
    "print(my_list_over['data']['u_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_list_unbiased['data']['x_a'])\n",
    "print(my_list_under['data']['x_a'])\n",
    "print(my_list_over['data']['x_a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**so what?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I may need aother function to see the boxplots of ppc and posterior distrubiton on interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(mylist= None, post= False, u_t = False, x_a = False, string='string'):\n",
    "    \n",
    "    if post is True: \n",
    "        # Boxplot for O_t, the variable of interest\n",
    "        a4_dims = (13, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        df1 = pd.DataFrame(data=mylist['trace']['o_t'], columns=range(1,13))\n",
    "        ax = sns.boxplot(data=df1)\n",
    "        ax.set_title(\"posterior samples of $O_t$ \"+string)\n",
    "        ax.set_xlabel('months')\n",
    "        ax.set_ylabel('$O_t$')   \n",
    "        ax = plt.plot(range(12), mylist['data']['o_t'],'ro')\n",
    "        fig.savefig('../latex/Figures/early_contamination_{}-o_t.png'.format(string))\n",
    "              \n",
    "    \n",
    "    if u_t is True:\n",
    "        # boxplot of ppc : u_t\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        df2= pd.DataFrame(data=mylist['ppc']['u_t'], columns=range(1,13))\n",
    "        ax = sns.boxplot(data=df2)\n",
    "        ax.set_title(\"posterior predictive values of $U_t$: \"+string)\n",
    "        ax.set_xlabel('months')\n",
    "        ax.set_ylabel('$U_t$') \n",
    "        ax= plt.plot(range(12), mylist['data']['u_t'],'ro')\n",
    "        fig.savefig('../latex/Figures/early_contamination_{}-u_t.png'.format(string))\n",
    "\n",
    "    \n",
    "    if x_a is True: \n",
    "        # boxplot of ppc : x_a\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        df3= pd.DataFrame(data=mylist['ppc']['x_a'])\n",
    "        ax=sns.boxplot(data=df3)\n",
    "        ax.set_title('posterior predictive values of $x_A$: '+string)\n",
    "        ax2 = plt.plot( mylist['data']['x_a'],'ro')\n",
    "        ax.set_xlabel('months')\n",
    "        ax.set_ylabel('$x_A$') \n",
    "        fig.savefig('../latex/Figures/early_contamination_{}-x_a.png'.format(string))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing $O_t$:  \n",
    "bias -2 vs unbiased vs bias +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization(my_list_unbiased, post= True, string='unbiased')\n",
    "\n",
    "visualization(my_list_under,post= True,string='underestimated')\n",
    "\n",
    "visualization(my_list_over,post= True,string='overestimated')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALSO maybe I should make another function to compare the three cases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing $U_t$  \n",
    "bias -2 vs unbiased vs bias +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization(my_list_unbiased, u_t= True, string='unbiased')\n",
    "\n",
    "visualization(my_list_under,u_t= True,string='underestimated')\n",
    "\n",
    "visualization(my_list_over,u_t= True,string='overestimated')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing $x_A$  \n",
    "bias -2 vs unbiased vs bias +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(my_list_unbiased, x_a= True, string='unbiased')\n",
    "\n",
    "visualization(my_list_under,x_a= True,string='underestimated')\n",
    "\n",
    "visualization(my_list_over,x_a= True,string='overestimated')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive plot?\n",
    "\n",
    "### Make a object rather than just a function ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dill.dump_session('notebook_env.db')\n",
    "# dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N is not well known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_N(data):\n",
    "    \n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # priors \n",
    "        p_a = pm.Beta('p_a', alpha=1, beta=1)\n",
    "        # note that this prior is to be changed later\n",
    "        mu_z = pm.Uniform('mu_z', -10, 0)\n",
    "        sigma_z = pm.Uniform('sigma_z',0,5)\n",
    "        \n",
    "        # uncertain N\n",
    "        N = pm.DiscreteUniform('N',lower=1,upper=2*10000)\n",
    "        \n",
    "        # latent variables\n",
    "        z_t = pm.Normal('z_t', mu=mu_z, sigma=sigma_z, shape=(12,))\n",
    "        lmb_t = pm.Deterministic('lmb_t', tt.exp(z_t))\n",
    "#       o_t = pm.Poisson('o_t', lmb_t*N)\n",
    "        o_t = pm.Gamma('o_t', mu=lmb_t*N , sigma=tt.sqrt(lmb_t*N), shape=(12,) )\n",
    "        # MCMC with discrete random variable is hard to do sampling...\n",
    "        # We approximate this to Gamma dist\n",
    "        \n",
    "        \n",
    "        #likelihood \n",
    "        pm.Poisson('u_t', o_t*p_a, observed=data['u_t'])\n",
    "        pm.Binomial('x_a', n=data['n_a'], p =p_a, observed=data['x_a'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_N = create_model_N(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_N:\n",
    "    trace_N = pm.sample(1000, chains=2, random_seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $p_A$ is Sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
